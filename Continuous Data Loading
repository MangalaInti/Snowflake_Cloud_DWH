**Snowipe**
Snowflake support loading of continuous data through a serverless service called Snowpipe
Snowpipe is serverless and has its own compute capacity, which means Snowpipe doesnâ€™t depend on virtual WH for processing. 
Compute capacity scaling up and scaling down of a Snowpipe is managed by Snowflake automatically 
Costs for Snowpipe are charged separately from virtual WH costs

--Snowpipe Data loading steps 
 1. Create target table in SDWH (Snowflake DWH)
 2. Creating a file format
 3. Creating S3 Bucket in AWS storage
 4. Creating an external stage in SDWH
 5. Creating a Snowpipe in SDWH
 6.Configure SQS Notifications
 7. Loadin source file to bucket
 8. Validate records in target.

**Streams**
Stream tracks any DML operations  made to a table. This process is commonly known as CDC(Change Data Capture)
1. Stream is DB object which is created over source table
2. This Stream object tracks all DML operations implemented on the source table
3. When we try to access the stream object, it return the histroic data in the same shape as the source object 
   that is the same column names and ordering,  with the following additional columns
      - METADATA$ACTION
      - METADATA$ISUPDATE
      - METADATA$ROW_ID

Streams are used for Change data capture. Streams may be combined with tasks to perform automatic processing of change data.

--- METADATA$ACTION
Indicates  the DML operation like INSERT, DELETE recorded

--METADATA$ISUPDATE
Indicates wheather the operation was part of UPDATE stmt . Updates to rows in the source object are represented as pair of DELETE and INSERT records
in the stream with metadata column METADATA$ISUPDATE value set to TRUE

Note that streams record the differences between two offsets
if a row is added and then updated in the current offset, the delta change is a new row
The METADATA$ISUPDATE row records a FALSE value

--METADATA$ROWID 
Specifies the unique and immutable ID for the row, which can be used to track changes to specific rows over time.

--Types of streams
1. Standard Stream 
2. Append only stream
3. Insert Only stream

Standard Stream :- Tracks all DML operation including the table truncation supported for streams on tables, directory tables and views
Append only stream:- Tracks only Insert operation only, supported for streams on tables, directory tables and views
Insert Only stream :- Tracks only Insert operation only, supported for streams on tables, directory tables and views

--Stream Steps

1. Create table public.customer
   ( cust_name string, cust_email string, discount_promo boolean)

2. Create another table discount_list 
  
    create table test_streams.public.discount_voucher_list
    (customer_email string);

3. Next create  stream on customer table
   
CREATE STREAM customer_changes on table customer

4. select * from customer_changes
5. To consume data from a stream, you must query and process the data into another table. 

6. Insert into test_streams.public.discount_voucher_list 
   select customer_email from customer_changes where discount_promo= 'Y' and 
   METADATA$ACTION = 'INSERT' AND METADATA$UPDATE = FALSE;



